{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the speedup\n",
    "### Extracting District Names into 9 Dictionaries\n",
    "Because there are only nine different scene locations in the downloaded dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if it was way more than 9, then could have sorted the file names first, then only the change of scene location, construct a new dictionary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import ogr, osr, gdal\n",
    "\n",
    "import fiona\n",
    "from shapely.geometry import Point, shape\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change this for Win7,macOS\n",
    "bases = \"C:\\Users\\deepak\\Desktop\\Repo\\Maps\\Districts\\Census\\Dist.shp\"\n",
    "# base_ = \"/Users/macbook/Documents/BTP/Satellite/Data/Maps/Districts/Census_2011\"\n",
    "fc = fiona.open(bases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_geocode(pt):\n",
    "    for feature in fc:\n",
    "        if shape(feature['geometry']).contains(pt):\n",
    "            return feature['properties']['DISTRICT']\n",
    "    return \"NRI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base2 = \"G:\\BTP\\Satellite\\Data\\Test\"  # Win7\n",
    "base = \"G:\\BTP\\Satellite\\Data\\Test2\"  # Win7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(filename, force=False):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "    if os.path.isdir(os.path.join(base,root)) and not force:\n",
    "        # You may override by setting force=True.\n",
    "        print('%s already present - Skipping extraction of %s' % (root, filename))\n",
    "    else:\n",
    "        print('Extracting data for %s' % root)\n",
    "        tar = tarfile.open(os.path.join(base,filename))\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(os.path.join(base,root))\n",
    "        tar.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LE07_L1GT_146039_20050702_20170115_01_T2 already present - Skipping extraction of LE07_L1GT_146039_20050702_20170115_01_T2.tar.gz\n",
      "LE07_L1GT_146040_20040512_20170120_01_T2 already present - Skipping extraction of LE07_L1GT_146040_20040512_20170120_01_T2.tar.gz\n",
      "LE07_L1GT_146041_20041222_20170117_01_T2 already present - Skipping extraction of LE07_L1GT_146041_20041222_20170117_01_T2.tar.gz\n",
      "LE07_L1GT_147039_20050725_20170114_01_T2 already present - Skipping extraction of LE07_L1GT_147039_20050725_20170114_01_T2.tar.gz\n",
      "LE07_L1GT_147040_20050506_20170116_01_T2 already present - Skipping extraction of LE07_L1GT_147040_20050506_20170116_01_T2.tar.gz\n",
      "LE07_L1GT_147041_20040807_20170119_01_T2 already present - Skipping extraction of LE07_L1GT_147041_20040807_20170119_01_T2.tar.gz\n",
      "LE07_L1GT_148039_20050918_20170113_01_T2 already present - Skipping extraction of LE07_L1GT_148039_20050918_20170113_01_T2.tar.gz\n",
      "LE07_L1GT_148040_20040627_20170120_01_T2 already present - Skipping extraction of LE07_L1GT_148040_20040627_20170120_01_T2.tar.gz\n",
      "LE07_L1GT_149039_20050128_20170117_01_T2 already present - Skipping extraction of LE07_L1GT_149039_20050128_20170117_01_T2.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# extracting for Test2\n",
    "for directory, subdirList, fileList in os.walk(base):\n",
    "    for filename in fileList:\n",
    "        if filename.endswith(\".tar.gz\"): \n",
    "            d = extract(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directories = [os.path.join(base, d) for d in sorted(os.listdir(base)) if os.path.isdir(os.path.join(base, d))]\n",
    "# print directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = gdal.Open(base2 + \"\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B1.TIF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "osgeo.gdal.Dataset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare one `ds` variable here itself, for the transformation of the coordinate system below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the new coordinate system\n",
    "wgs84_wkt = \"\"\"\n",
    "GEOGCS[\"WGS 84\",\n",
    "    DATUM[\"WGS_1984\",\n",
    "        SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
    "            AUTHORITY[\"EPSG\",\"7030\"]],\n",
    "        AUTHORITY[\"EPSG\",\"6326\"]],\n",
    "    PRIMEM[\"Greenwich\",0,\n",
    "        AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "    UNIT[\"degree\",0.01745329251994328,\n",
    "        AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "    AUTHORITY[\"EPSG\",\"4326\"]]\"\"\"\n",
    "new_cs = osr.SpatialReference()\n",
    "new_cs.ImportFromWkt(wgs84_wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(dsx):\n",
    "    old_cs= osr.SpatialReference()\n",
    "    old_cs.ImportFromWkt(dsx.GetProjectionRef())\n",
    "    trs = osr.CoordinateTransformation(old_cs,new_cs) \n",
    "    return trs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pixel2coord(x, y, xoff, a, b, yoff, d, e):\n",
    "    \"\"\"Returns global coordinates from coordinates x,y of the pixel\"\"\"\n",
    "    xp = a * x + b * y + xoff\n",
    "    yp = d * x + e * y + yoff\n",
    "    return(xp, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicts = [[],[],[],[],[],[],[],[],[]]\n",
    "dictr = [(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0)]\n",
    "dicti = {\"146039\":0, \"146040\":1, \"146041\":2, \"147039\":3, \"147040\":4, \"147041\":5, \"148039\":6, \"148040\":7, \"149039\":8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_146039_20050702_20170115_01_T2\\LE07_L1GT_146039_20050702_20170115_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_146040_20040512_20170120_01_T2\\LE07_L1GT_146040_20040512_20170120_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_146041_20041222_20170117_01_T2\\LE07_L1GT_146041_20041222_20170117_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_147039_20050725_20170114_01_T2\\LE07_L1GT_147039_20050725_20170114_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_147040_20050506_20170116_01_T2\\LE07_L1GT_147040_20050506_20170116_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_147041_20040807_20170119_01_T2\\LE07_L1GT_147041_20040807_20170119_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_148039_20050918_20170113_01_T2\\LE07_L1GT_148039_20050918_20170113_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_148040_20040627_20170120_01_T2\\LE07_L1GT_148040_20040627_20170120_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_149039_20050128_20170117_01_T2\\LE07_L1GT_149039_20050128_20170117_01_T2_B1.TIF\n",
      "22027.7967823\n",
      "Seconds\n"
     ]
    }
   ],
   "source": [
    "stx = timeit.default_timer()\n",
    "\n",
    "for directory in directories:\n",
    "    \n",
    "    \"\"\" Identifying Month, Year, Spacecraft ID \"\"\"\n",
    "    date = directory.split('\\\\')[-1].split('_')[3] # Change for Win7\n",
    "    satx = directory.split('\\\\')[-1][3]\n",
    "    month = date[4:6]\n",
    "    year = date[0:4]\n",
    "    \n",
    "    scene = directory.split('\\\\')[-1].split('_')[2]\n",
    "    index = dicti[scene]\n",
    "    \n",
    "    #if index != 1: continue\n",
    "    \n",
    "    \"\"\" Visiting every GeoTIFF file \"\"\" \n",
    "    for _,_,files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            \n",
    "            if filename.endswith(\".TIF\"):\n",
    "                \n",
    "                if filename[-5] == '2': break\n",
    "                \n",
    "                print os.path.join(directory,filename)\n",
    "                \n",
    "                ds = gdal.Open(os.path.join(directory,filename))\n",
    "                if ds == None: continue\n",
    "                col, row, _ = ds.RasterXSize, ds.RasterYSize, ds.RasterCount\n",
    "                xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
    "                #--------------------\n",
    "                transform = func(ds)\n",
    "                #--------------------\n",
    "                \n",
    "                dictr[index] = (col,row)\n",
    "                \n",
    "                \"\"\" Now go to each pixel, find its lat,lon. Hence its district, and the pixel value \"\"\"\n",
    "                for i in range(0,col,col/k):\n",
    "                    for j in range(0,row,row/k):\n",
    "                        \n",
    "                        ########### fetching the lat and lon coordinates \n",
    "                        x,y = pixel2coord(i, j, xoff, a, b, yoff, d, e)\n",
    "                        lonx, latx, z = transform.TransformPoint(x,y)\n",
    "                        \n",
    "                        \n",
    "                        ########### fetching the name of district\n",
    "                        \n",
    "                        point = Point(lonx,latx)\n",
    "                        district = reverse_geocode(point)\n",
    "                        \n",
    "                        dicts[index].append(district)\n",
    "                        \n",
    "#                         #----------------------------------------------------------\n",
    "#                         if filename[-5] == '1':\n",
    "#                             point = Point(lonx,latx)\n",
    "#                             district = reverse_geocode(point)\n",
    "#                             dicts[i][str(lonx)+str(latx)] = district\n",
    "#                         else:\n",
    "#                             print \"-------------------- !!!!!!! -------------------\"\n",
    "#                             district = dictx[str(lonx)+str(latx)]\n",
    "#                         #----------------------------------------------------------\n",
    "                        \n",
    "            \n",
    "                            \n",
    "elapsed = timeit.default_timer() - stx\n",
    "print (elapsed)\n",
    "print \"Seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7981, 7271), (7741, 7001), (7761, 7021), (7811, 7051), (7801, 7071), (7821, 7051), (7871, 7111), (7861, 7131), (7941, 7181)]\n"
     ]
    }
   ],
   "source": [
    "print dictr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.3540173718\n",
      "74.8772487691\n",
      "Hanumangarh\n"
     ]
    }
   ],
   "source": [
    "print latx\n",
    "print lonx\n",
    "print district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print len(dicts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = \"G:\\BTP\\Satellite\\Data\\Bulk\\Landsat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = \"G:\\BTP\\Satellite\\Data\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directories = [os.path.join(base, d) for d in sorted(os.listdir(base)) if os.path.isdir(os.path.join(base, d))]\n",
    "# print directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>ind_district</th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>phosphorus</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>1999</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>37991.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96800.0</td>\n",
       "      <td>75400.0</td>\n",
       "      <td>643.720</td>\n",
       "      <td>881.473</td>\n",
       "      <td>2.765971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2000</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>39905.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>96800.0</td>\n",
       "      <td>767.351</td>\n",
       "      <td>643.720</td>\n",
       "      <td>2.949004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>32878.0</td>\n",
       "      <td>95609.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>579.338</td>\n",
       "      <td>767.351</td>\n",
       "      <td>2.907993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2002</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>29066.0</td>\n",
       "      <td>66329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95609.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>540.070</td>\n",
       "      <td>579.338</td>\n",
       "      <td>2.282013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2005</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>25008.0</td>\n",
       "      <td>69972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85051.0</td>\n",
       "      <td>44891.0</td>\n",
       "      <td>819.700</td>\n",
       "      <td>564.500</td>\n",
       "      <td>2.797985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_Name ind_district  Crop_Year  Season  Crop     Area  Production  \\\n",
       "0  Andhra Pradesh    anantapur       1999  kharif  Rice  37991.0    105082.0   \n",
       "1  Andhra Pradesh    anantapur       2000  kharif  Rice  39905.0    117680.0   \n",
       "2  Andhra Pradesh    anantapur       2001  kharif  Rice  32878.0     95609.0   \n",
       "3  Andhra Pradesh    anantapur       2002  kharif  Rice  29066.0     66329.0   \n",
       "4  Andhra Pradesh    anantapur       2005  kharif  Rice  25008.0     69972.0   \n",
       "\n",
       "   phosphorus        X1        X2       X3       X4     value  \n",
       "0         0.0   96800.0   75400.0  643.720  881.473  2.765971  \n",
       "1         0.0  105082.0   96800.0  767.351  643.720  2.949004  \n",
       "2         0.0  117680.0  105082.0  579.338  767.351  2.907993  \n",
       "3         0.0   95609.0  117680.0  540.070  579.338  2.282013  \n",
       "4         0.0   85051.0   44891.0  819.700  564.500  2.797985  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ricep = pd.read_csv(\"C:\\Users\\deepak\\Desktop\\Repo\\BTP\\Ricep.csv\")\n",
    "ricep = ricep.drop([\"Unnamed: 0\"],axis=1)\n",
    "ricep[\"value\"] = ricep[\"Production\"]/ricep[\"Area\"]\n",
    "ricep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.empty((ricep.shape[0],1))*np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" 'features' contain collumn indexes for the new features \"\"\"\n",
    "\"\"\" 'dictn' is the dictionary mapping name of collumn index to the index number \"\"\"\n",
    "features = []\n",
    "dictn = {}\n",
    "k = 13\n",
    "for i in range(1,13):\n",
    "    for j in range(1,11):\n",
    "        s = str(i) + \"_B\" + str(j) + \"_\"\n",
    "        features.append(s+\"M\")\n",
    "        features.append(s+\"V\")\n",
    "        dictn[s+\"M\"] = k\n",
    "        dictn[s+\"V\"] = k+1\n",
    "        k = k+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,13):\n",
    "    for j in range(1,11):\n",
    "        s = str(i) + \"_B\" + str(j) + \"_\"\n",
    "        features.append(s+\"Mn\")\n",
    "        features.append(s+\"Vn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(index=range(ricep.shape[0]),columns=features)\n",
    "ricex = pd.concat([ricep,tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 50\n",
    "hits = 0\n",
    "times = [0,0,0,0,0,0,0,0]\n",
    "nums = [0,0,0,0,0,0,0,0]\n",
    "\n",
    "bx = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B2.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B3.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B4.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B5.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B6_VCID_1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B6_VCID_2.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B7.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_BQA.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B2.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B3.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B4.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B5.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B6_VCID_1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B6_VCID_2.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B7.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_BQA.TIF\n",
      "122.503495055\n",
      "Seconds\n"
     ]
    }
   ],
   "source": [
    "stx = timeit.default_timer()\n",
    "\n",
    "for directory in directories:\n",
    "    \n",
    "#     if bx: continue\n",
    "#     else: bx = True\n",
    "    \n",
    "    \"\"\" Identifying Month, Year, Spacecraft ID \"\"\"\n",
    "    date = directory.split('\\\\')[-1].split('_')[3] # Change for Win7\n",
    "    satx = directory.split('\\\\')[-1][3]\n",
    "    month = date[4:6]\n",
    "    year = date[0:4]\n",
    "    \n",
    "    scene = directory.split('\\\\')[-1].split('_')[2]\n",
    "    index = dicti[scene]\n",
    "    \n",
    "    \"\"\" Visiting every GeoTIFF file \"\"\" \n",
    "    for _,_,files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            \n",
    "            \n",
    "            if filename.endswith(\".TIF\"):\n",
    "                \n",
    "                if filename[-5] == '8': continue\n",
    "                \n",
    "                print os.path.join(directory,filename)\n",
    "                \n",
    "                ds = gdal.Open(os.path.join(directory,filename))\n",
    "                if ds == None: continue\n",
    "                col, row, _ = ds.RasterXSize, ds.RasterYSize, ds.RasterCount\n",
    "                xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
    "                \n",
    "                ind = -1\n",
    "                for i in range(0,col,col/k):\n",
    "                    for j in range(0,row,row/k):\n",
    "                        \n",
    "                        ind += 1\n",
    "                        if ind>2600: break\n",
    "                            \n",
    "                        st = timeit.default_timer()\n",
    "                        ########### fetching the lat and lon coordinates \n",
    "                        times[0] += timeit.default_timer() - st\n",
    "                        nums[0] += 1\n",
    "                        \n",
    "                        \n",
    "                        st = timeit.default_timer()\n",
    "                        ########### fetching the name of district\n",
    "                        district = dicts[index][ind]\n",
    "                        #----------------------------------------------------------\n",
    "                        times[1] += timeit.default_timer() - st\n",
    "                        nums[1] += 1\n",
    "                        \n",
    "                        if district == \"NRI\": continue\n",
    "                        \n",
    "                        \n",
    "                        st = timeit.default_timer()\n",
    "                        ########### Locating the row in DataFrame which we want to update\n",
    "                        district = district.lower()\n",
    "                        district = district.strip()\n",
    "                        r = ricex.index[(ricex['ind_district'] == district) & (ricex['Crop_Year'] == int(year))].tolist()\n",
    "                        times[3] += timeit.default_timer() - st\n",
    "                        nums[3] += 1\n",
    "                        \n",
    "                        \n",
    "                        if len(r) == 1:\n",
    "                            \n",
    "                            st = timeit.default_timer()\n",
    "                            ########### The pixel value for that location\n",
    "                            px,py = i,j\n",
    "                            pix = ds.ReadAsArray(px,py,1,1)\n",
    "                            pix = int(pix[0][0])\n",
    "                            times[2] += timeit.default_timer() - st\n",
    "                            nums[2] += 1\n",
    "                            \n",
    "                            \n",
    "                            st = timeit.default_timer()\n",
    "                            \"\"\" Found the row, so now ..\"\"\"\n",
    "                            \"\"\" Find Collumn index corresponding to Month, Band \"\"\"\n",
    "                            hits = hits + 1\n",
    "                            #print (\"Hits: \", hits)\n",
    "                            ####### Band Number ########\n",
    "                            band = filename.split(\"\\\\\")[-1].split(\"_\")[7:][0].split(\".\")[0][1]\n",
    "                            bnd = band\n",
    "                            if band == '6':\n",
    "                                if filename.split(\"\\\\\")[-1].split(\"_\")[7:][2][0] == '1':\n",
    "                                    bnd = band\n",
    "                                else:\n",
    "                                    bnd = '9'\n",
    "                            elif band == 'Q':\n",
    "                                bnd = '10'\n",
    "                            \n",
    "                            sm = month + \"_B\" + bnd +\"_M\"\n",
    "                            \n",
    "                            cm = dictn[sm]\n",
    "                            \n",
    "                            r = r[0]\n",
    "                            # cm is the collumn indexe for mean\n",
    "                            # r[0] is the row index\n",
    "                            times[4] += timeit.default_timer() - st\n",
    "                            nums[4] += 1\n",
    "                            \n",
    "                            \n",
    "                            ##### Checking if values are null ...\n",
    "                            valm = ricex.iloc[r,cm]\n",
    "                            if pd.isnull(valm): \n",
    "                                \n",
    "                                st = timeit.default_timer()\n",
    "                                ricex.iloc[r,cm] = int(pix)\n",
    "                                ricex.iloc[r,cm+1] = int(pix*pix)\n",
    "                                ricex.iloc[r,cm+240] = 1\n",
    "                                times[5] += timeit.default_timer() - st\n",
    "                                nums[5] += 1\n",
    "                        \n",
    "                                continue\n",
    "                                \n",
    "                                \n",
    "                            st = timeit.default_timer()\n",
    "                            ##### if the values are not null ...\n",
    "                            valv = int(ricex.iloc[r,cm+1])\n",
    "                            n = int(ricex.iloc[r,cm+240])\n",
    "                            n = n+1\n",
    "                            times[6] += timeit.default_timer() - st\n",
    "                            nums[6] += 1\n",
    "                        \n",
    "                            \n",
    "                            \n",
    "                            st = timeit.default_timer()\n",
    "                            # Mean & Variance update\n",
    "                            ricex.iloc[r,cm] = valm + (pix-valm)/n\n",
    "                            ricex.iloc[r,cm+1] = ((n-2)/(n-1))*valv + (pix-valm)*(pix-valm)/n\n",
    "                            ricex.iloc[r,cm+240] = n\n",
    "                            \n",
    "                            times[7] += timeit.default_timer() - st\n",
    "                            nums[7] += 1\n",
    "                        \n",
    "                            \n",
    "                        \n",
    "                            #print (\"No match for the district \" + district + \" for the year \" + year)\n",
    "                            \n",
    "                            \n",
    "elapsed = timeit.default_timer() - stx\n",
    "print (elapsed)\n",
    "print \"Seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.011475057348434348, 0.035648974422656465, 28.352838132581383, 58.64514798646269, 0.1363394056679681, 0.39012996186647797, 3.361048744081927, 30.0258021067566]\n",
      "[46818, 46818, 20916, 46521, 20916, 216, 20700, 20700]\n",
      "20916\n"
     ]
    }
   ],
   "source": [
    "print times\n",
    "print nums\n",
    "print hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2.45099264138e-07\n",
      "1: 7.61437362182e-07\n",
      "2: 0.00135555737869\n",
      "3: 0.00126061666745\n",
      "4: 6.51842635628e-06\n",
      "5: 0.00180615723086\n",
      "6: 0.000162369504545\n",
      "7: 0.00145052184091\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    x = times[i]/nums[i]\n",
    "    print (str(i) + \": \" + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
