{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Features from GeoTiff Files\n",
    "From GeoTiff Files available for India over a period of more than 20 years, we want to generate features from those files for the problem of prediction of district wise crop yield in India."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to gdal package, had to make a separate environment using conda. So install packages for this notebook in that environment itself. Check from the anaconda prompt, the names of all the envs are available: \n",
    "```shell\n",
    "$ conda info --envs \n",
    "$ activate env_name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import ogr, osr, gdal\n",
    "\n",
    "import fiona\n",
    "from shapely.geometry import Point, shape\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Windows\n",
    "``` python\n",
    "base_ = \"C:\\Users\\deepak\\Desktop\\Repo\\Maps\\Districts\\Census_2011\"\n",
    "```\n",
    "- For macOS\n",
    "``` python\n",
    "base_ = \"/Users/macbook/Documents/BTP/Satellite/Data/Maps/Districts/Census_2011\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change this for Win7,macOS\n",
    "bases = \"C:\\Users\\deepak\\Desktop\\Repo\\Maps\\Districts\\Census\\Dist.shp\"\n",
    "# base_ = \"/Users/macbook/Documents/BTP/Satellite/Data/Maps/Districts/Census_2011\"\n",
    "fc = fiona.open(bases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_geocode(pt):\n",
    "    for feature in fc:\n",
    "        if shape(feature['geometry']).contains(pt):\n",
    "            return feature['properties']['DISTRICT']\n",
    "    return \"NRI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base = \"/Users/macbook/Documents/BTP/Satellite/Data/Sat\" # macOS\n",
    "base = \"G:\\BTP\\Satellite\\Data\\Test\"  # Win7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# b = True\n",
    "# for directory, subdirList, fileList in os.walk(base):\n",
    "# #     if b:\n",
    "# #         b = False\n",
    "# #         continue\n",
    "#     #print (\"Directory: \" + directory)\n",
    "#     for filename in fileList:\n",
    "#         if filename[0] != '.': print (\"\\t\" + filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(filename, force=False):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "    if os.path.isdir(os.path.join(base,root)) and not force:\n",
    "        # You may override by setting force=True.\n",
    "        print('%s already present - Skipping extraction of %s' % (root, filename))\n",
    "    else:\n",
    "        print('Extracting data for %s' % root)\n",
    "        tar = tarfile.open(os.path.join(base,filename))\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(os.path.join(base,root))\n",
    "        tar.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LE07_L1TP_146039_20101223_20161211_01_T1 already present - Skipping extraction of LE07_L1TP_146039_20101223_20161211_01_T1.tar.gz\n",
      "LE07_L1TP_146041_20101223_20161211_01_T1 already present - Skipping extraction of LE07_L1TP_146041_20101223_20161211_01_T1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# extracting all the tar files ... (if not extracted)\n",
    "for directory, subdirList, fileList in os.walk(base):\n",
    "    for filename in fileList:\n",
    "        if filename.endswith(\".tar.gz\"): \n",
    "            d = extract(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directories = [os.path.join(base, d) for d in sorted(os.listdir(base)) if os.path.isdir(os.path.join(base, d))]\n",
    "# print directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = gdal.Open(base + \"\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B1.TIF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare one `ds` variable here itself, for the transformation of the coordinate system below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the existing coordinate system\n",
    "old_cs= osr.SpatialReference()\n",
    "old_cs.ImportFromWkt(ds.GetProjectionRef())\n",
    "\n",
    "# create the new coordinate system\n",
    "wgs84_wkt = \"\"\"\n",
    "GEOGCS[\"WGS 84\",\n",
    "    DATUM[\"WGS_1984\",\n",
    "        SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
    "            AUTHORITY[\"EPSG\",\"7030\"]],\n",
    "        AUTHORITY[\"EPSG\",\"6326\"]],\n",
    "    PRIMEM[\"Greenwich\",0,\n",
    "        AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "    UNIT[\"degree\",0.01745329251994328,\n",
    "        AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "    AUTHORITY[\"EPSG\",\"4326\"]]\"\"\"\n",
    "new_cs = osr.SpatialReference()\n",
    "new_cs.ImportFromWkt(wgs84_wkt)\n",
    "\n",
    "# create a transform object to convert between coordinate systems\n",
    "transform = osr.CoordinateTransformation(old_cs,new_cs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pixel2coord(x, y, xoff, a, b, yoff, d, e):\n",
    "    \"\"\"Returns global coordinates from coordinates x,y of the pixel\"\"\"\n",
    "    xp = a * x + b * y + xoff\n",
    "    yp = d * x + e * y + yoff\n",
    "    return(xp, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>ind_district</th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>phosphorus</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>1999</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>37991.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96800.0</td>\n",
       "      <td>75400.0</td>\n",
       "      <td>643.720</td>\n",
       "      <td>881.473</td>\n",
       "      <td>2.765971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2000</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>39905.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>96800.0</td>\n",
       "      <td>767.351</td>\n",
       "      <td>643.720</td>\n",
       "      <td>2.949004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>32878.0</td>\n",
       "      <td>95609.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>579.338</td>\n",
       "      <td>767.351</td>\n",
       "      <td>2.907993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2002</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>29066.0</td>\n",
       "      <td>66329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95609.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>540.070</td>\n",
       "      <td>579.338</td>\n",
       "      <td>2.282013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2005</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>25008.0</td>\n",
       "      <td>69972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85051.0</td>\n",
       "      <td>44891.0</td>\n",
       "      <td>819.700</td>\n",
       "      <td>564.500</td>\n",
       "      <td>2.797985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_Name ind_district  Crop_Year  Season  Crop     Area  Production  \\\n",
       "0  Andhra Pradesh    anantapur       1999  kharif  Rice  37991.0    105082.0   \n",
       "1  Andhra Pradesh    anantapur       2000  kharif  Rice  39905.0    117680.0   \n",
       "2  Andhra Pradesh    anantapur       2001  kharif  Rice  32878.0     95609.0   \n",
       "3  Andhra Pradesh    anantapur       2002  kharif  Rice  29066.0     66329.0   \n",
       "4  Andhra Pradesh    anantapur       2005  kharif  Rice  25008.0     69972.0   \n",
       "\n",
       "   phosphorus        X1        X2       X3       X4     value  \n",
       "0         0.0   96800.0   75400.0  643.720  881.473  2.765971  \n",
       "1         0.0  105082.0   96800.0  767.351  643.720  2.949004  \n",
       "2         0.0  117680.0  105082.0  579.338  767.351  2.907993  \n",
       "3         0.0   95609.0  117680.0  540.070  579.338  2.282013  \n",
       "4         0.0   85051.0   44891.0  819.700  564.500  2.797985  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ricep = pd.read_csv(\"C:\\Users\\deepak\\Desktop\\Repo\\BTP\\Ricep.csv\")\n",
    "ricep = ricep.drop([\"Unnamed: 0\"],axis=1)\n",
    "ricep[\"value\"] = ricep[\"Production\"]/ricep[\"Area\"]\n",
    "ricep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New features\n",
    "----\n",
    "> 12 months (Numbered 1 to 12)\n",
    ">> 10 TIF files (12 for SAT_8)\n",
    ">>> Mean & Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.empty((ricep.shape[0],1))*np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" 'features' contain collumn indexes for the new features \"\"\"\n",
    "\"\"\" 'dictn' is the dictionary mapping name of collumn index to the index number \"\"\"\n",
    "features = []\n",
    "dictn = {}\n",
    "k = 13\n",
    "for i in range(1,13):\n",
    "    for j in range(1,11):\n",
    "        s = str(i) + \"_B\" + str(j) + \"_\"\n",
    "        features.append(s+\"M\")\n",
    "        features.append(s+\"V\")\n",
    "        dictn[s+\"M\"] = k\n",
    "        dictn[s+\"V\"] = k+1\n",
    "        k = k+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,13):\n",
    "    for j in range(1,11):\n",
    "        s = str(i) + \"_B\" + str(j) + \"_\"\n",
    "        features.append(s+\"Mn\")\n",
    "        features.append(s+\"Vn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(index=range(ricep.shape[0]),columns=features)\n",
    "ricex = pd.concat([ricep,tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>ind_district</th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>phosphorus</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>...</th>\n",
       "      <th>12_B6_Mn</th>\n",
       "      <th>12_B6_Vn</th>\n",
       "      <th>12_B7_Mn</th>\n",
       "      <th>12_B7_Vn</th>\n",
       "      <th>12_B8_Mn</th>\n",
       "      <th>12_B8_Vn</th>\n",
       "      <th>12_B9_Mn</th>\n",
       "      <th>12_B9_Vn</th>\n",
       "      <th>12_B10_Mn</th>\n",
       "      <th>12_B10_Vn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>1999</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>37991.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96800.0</td>\n",
       "      <td>75400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2000</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>39905.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>96800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>32878.0</td>\n",
       "      <td>95609.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2002</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>29066.0</td>\n",
       "      <td>66329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95609.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2005</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>25008.0</td>\n",
       "      <td>69972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85051.0</td>\n",
       "      <td>44891.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 493 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_Name ind_district  Crop_Year  Season  Crop     Area  Production  \\\n",
       "0  Andhra Pradesh    anantapur       1999  kharif  Rice  37991.0    105082.0   \n",
       "1  Andhra Pradesh    anantapur       2000  kharif  Rice  39905.0    117680.0   \n",
       "2  Andhra Pradesh    anantapur       2001  kharif  Rice  32878.0     95609.0   \n",
       "3  Andhra Pradesh    anantapur       2002  kharif  Rice  29066.0     66329.0   \n",
       "4  Andhra Pradesh    anantapur       2005  kharif  Rice  25008.0     69972.0   \n",
       "\n",
       "   phosphorus        X1        X2    ...     12_B6_Mn  12_B6_Vn  12_B7_Mn  \\\n",
       "0         0.0   96800.0   75400.0    ...          NaN       NaN       NaN   \n",
       "1         0.0  105082.0   96800.0    ...          NaN       NaN       NaN   \n",
       "2         0.0  117680.0  105082.0    ...          NaN       NaN       NaN   \n",
       "3         0.0   95609.0  117680.0    ...          NaN       NaN       NaN   \n",
       "4         0.0   85051.0   44891.0    ...          NaN       NaN       NaN   \n",
       "\n",
       "  12_B7_Vn 12_B8_Mn 12_B8_Vn 12_B9_Mn 12_B9_Vn 12_B10_Mn 12_B10_Vn  \n",
       "0      NaN      NaN      NaN      NaN      NaN       NaN       NaN  \n",
       "1      NaN      NaN      NaN      NaN      NaN       NaN       NaN  \n",
       "2      NaN      NaN      NaN      NaN      NaN       NaN       NaN  \n",
       "3      NaN      NaN      NaN      NaN      NaN       NaN       NaN  \n",
       "4      NaN      NaN      NaN      NaN      NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 493 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ricex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "hits = 0\n",
    "times = [0,0,0,0,0,0,0,0]\n",
    "nums = [0,0,0,0,0,0,0,0]\n",
    "\n",
    "bx = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B1.TIF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepak\\Anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\ipykernel_launcher.py:161: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "C:\\Users\\deepak\\Anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\ipykernel_launcher.py:140: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "C:\\Users\\deepak\\Anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\ipykernel_launcher.py:160: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B1.TIF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for directory in directories:\n",
    "    \n",
    "    if bx: continue\n",
    "    else: bx = True\n",
    "    \n",
    "    dictx = {}\n",
    "    \n",
    "    \"\"\" Identifying Month, Year, Spacecraft ID \"\"\"\n",
    "    date = directory.split('\\\\')[-1].split('_')[3] # Change for Win7\n",
    "    satx = directory.split('\\\\')[-1][3]\n",
    "    month = date[4:6]\n",
    "    year = date[0:4]\n",
    "    \n",
    "    \"\"\" Visiting every GeoTIFF file \"\"\" \n",
    "    for _,_,files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            \n",
    "            # make sure not going into the extra folders\n",
    "            \n",
    "            if filename.endswith(\".TIF\"):\n",
    "                \n",
    "                if int(filename[-5]) > 5: break \n",
    "                #--------------------------------------------------------------------------------------\n",
    "                # Check for a single iteration. Which step takes the longest time.\n",
    "                # improve that step\n",
    "                \n",
    "                # Do it all for B1.tif only.\n",
    "                # for others save the row indexes found in B1's iteration\n",
    "                # so dont have to search the dataframe again and again.\n",
    "                # but keep track of the pixels which were not found, so have to skip them too\n",
    "                # so that correct pixel value goes to the correct row in dataframe\n",
    "                # have to traverse the tiff file to get the pixel values\n",
    "                \n",
    "                # what all steps are common for all the 10 tif files\n",
    "                # the district search from the pixel's lat,lon coordinates\n",
    "                # the row index search using district and the year\n",
    "                # the same n is read and wrote for all the ...\n",
    "                \n",
    "                # If nothing works, maybe we can reduce the number of features, by just visiting \n",
    "                # First 5 TIF files for each scene.\n",
    "                #--------------------------------------------------------------------------------------\n",
    "                \n",
    "                \n",
    "                print os.path.join(directory,filename)\n",
    "                \n",
    "                ds = gdal.Open(os.path.join(directory,filename))\n",
    "                if ds == None: continue\n",
    "                col, row, _ = ds.RasterXSize, ds.RasterYSize, ds.RasterCount\n",
    "                xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
    "                \n",
    "                \"\"\" Now go to each pixel, find its lat,lon. Hence its district, and the pixel value \"\"\"\n",
    "                \"\"\" Find the row with same (Year,District), in Crop Dataset. \"\"\"\n",
    "                \"\"\" Find the feature using Month, Band, SATx \"\"\"\n",
    "                \"\"\" For this have to find Mean & Variance \"\"\"\n",
    "                \n",
    "                for i in range(0,col,col/k):\n",
    "                    for j in range(0,row,row/k):\n",
    "                        \n",
    "                        st = timeit.default_timer()\n",
    "                        ########### fetching the lat and lon coordinates \n",
    "                        x,y = pixel2coord(i, j, xoff, a, b, yoff, d, e)\n",
    "                        lonx, latx, z = transform.TransformPoint(x,y)\n",
    "                        times[0] += timeit.default_timer() - st\n",
    "                        nums[0] += 1\n",
    "                        \n",
    "                        \n",
    "                        st = timeit.default_timer()\n",
    "                        ########### fetching the name of district\n",
    "                        \n",
    "                        district = \"\"\n",
    "                        #----------------------------------------------------------\n",
    "                        if filename[-5] == '1':\n",
    "                            point = Point(lonx,latx)\n",
    "                            district = reverse_geocode(point)\n",
    "                            dictx[str(lonx)+str(latx)] = district\n",
    "                        else:\n",
    "                            district = dictx[str(lonx)+str(latx)]\n",
    "                        #----------------------------------------------------------\n",
    "                        times[1] += timeit.default_timer() - st\n",
    "                        nums[1] += 1\n",
    "                        \n",
    "                        if district == \"NRI\": continue\n",
    "                        \n",
    "                        \n",
    "                        st = timeit.default_timer()\n",
    "                        ########### Locating the row in DataFrame which we want to update\n",
    "                        district = district.lower()\n",
    "                        district = district.strip()\n",
    "                        r = ricex.index[(ricex['ind_district'] == district) & (ricex['Crop_Year'] == int(year))].tolist()\n",
    "                        times[3] += timeit.default_timer() - st\n",
    "                        nums[3] += 1\n",
    "                        \n",
    "                        \n",
    "                        if len(r) == 1:\n",
    "                            \n",
    "                            st = timeit.default_timer()\n",
    "                            ########### The pixel value for that location\n",
    "                            px,py = i,j\n",
    "                            pix = ds.ReadAsArray(px,py,1,1)\n",
    "                            pix = pix[0][0]\n",
    "                            times[2] += timeit.default_timer() - st\n",
    "                            nums[2] += 1\n",
    "                            \n",
    "                            \n",
    "                            st = timeit.default_timer()\n",
    "                            \"\"\" Found the row, so now ..\"\"\"\n",
    "                            \"\"\" Find Collumn index corresponding to Month, Band \"\"\"\n",
    "                            hits = hits + 1\n",
    "                            #print (\"Hits: \", hits)\n",
    "                            ####### Band Number ########\n",
    "                            band = filename.split(\"\\\\\")[-1].split(\"_\")[7:][0].split(\".\")[0][1]\n",
    "                            bnd = band\n",
    "                            if band == '6':\n",
    "                                if filename.split(\"\\\\\")[-1].split(\"_\")[7:][2][0] == '1':\n",
    "                                    bnd = band\n",
    "                                else:\n",
    "                                    bnd = '9'\n",
    "                            elif band == 'Q':\n",
    "                                bnd = '10'\n",
    "                            \n",
    "                            sm = month + \"_B\" + bnd +\"_M\"\n",
    "                            \n",
    "                            cm = dictn[sm]\n",
    "                            \n",
    "                            r = r[0]\n",
    "                            # cm is the collumn indexe for mean\n",
    "                            # r[0] is the row index\n",
    "                            times[4] += timeit.default_timer() - st\n",
    "                            nums[4] += 1\n",
    "                            \n",
    "                            \n",
    "                            ##### Checking if values are null ...\n",
    "                            valm = ricex.iloc[r,cm]\n",
    "                            if pd.isnull(valm): \n",
    "                                \n",
    "                                st = timeit.default_timer()\n",
    "                                ricex.iloc[r,cm] = pix\n",
    "                                ricex.iloc[r,cm+1] = pix*pix\n",
    "                                ricex.iloc[r,cm+240] = 1\n",
    "                                times[5] += timeit.default_timer() - st\n",
    "                                nums[5] += 1\n",
    "                        \n",
    "                                continue\n",
    "                                \n",
    "                                \n",
    "                            st = timeit.default_timer()\n",
    "                            ##### if the values are not null ...\n",
    "                            valv = ricex.iloc[r,cm+1]\n",
    "                            n = ricex.iloc[r,cm+240]\n",
    "                            n = n+1\n",
    "                            times[6] += timeit.default_timer() - st\n",
    "                            nums[6] += 1\n",
    "                        \n",
    "                            \n",
    "                            \n",
    "                            st = timeit.default_timer()\n",
    "                            # Mean & Variance update\n",
    "                            ricex.iloc[r,cm] = valm + (pix-valm)/n\n",
    "                            ricex.iloc[r,cm+1] = ((n-2)/(n-1))*valv + (pix-valm)*(pix-valm)/n\n",
    "                            ricex.iloc[r,cm+240] = n\n",
    "                            \n",
    "                            times[7] += timeit.default_timer() - st\n",
    "                            nums[7] += 1\n",
    "                        \n",
    "                            \n",
    "                        \n",
    "                            #print (\"No match for the district \" + district + \" for the year \" + year)\n",
    "                            \n",
    "                            \n",
    "# elapsed = timeit.default_timer() - start_time\n",
    "# print (elapsed)\n",
    "# print \"Seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'84.531157576727.5992839222': 'NRI', '84.034358494927.0459840145': u'Pashchim Champaran', '82.845297018427.6319704051': 'NRI', '83.804214814827.4275199192': 'NRI', '83.068858499926.6866117783': u'Sant Kabir Nagar', '82.588241726226.5043183605': u'Ambedkar Nagar', '83.828604443928.3688406085': 'NRI', '83.555153168427.0555096815': u'Maharajganj', '82.601523918527.446540203': u'Balrampur', '84.765316713427.4048533365': 'NRI', '83.572568797527.8087734778': 'NRI', '84.771732044827.592947675': 'NRI', '82.351787627726.6952508853': u'Basti', '84.301872606427.981569351': 'NRI', '83.563776291327.4321530355': u'Maharajganj', '83.794785450727.0509504679': u'Kushinagar', '82.835951504527.0667403943': u'Siddharth Nagar', '84.055028963227.7989379885': 'NRI', '83.785538624626.6743578724': u'Deoria', '82.607020863927.8233916953': 'NRI', '82.612625314728.2002215909': 'NRI', '84.495971376526.4703222247': u'Gopalganj', '84.791354865228.1571916124': 'NRI', '83.079218213727.2517933783': u'Siddharth Nagar', '82.826876174126.5014620426': u'Ambedkar Nagar', '83.577029347327.9970750308': 'NRI', '84.04459323827.4224729688': u'Pashchim Champaran', '83.3352955528.0013957316': 'NRI', '83.568151216927.6204661359': 'NRI', '83.780982852526.4860529766': u'Deoria', '82.367903565728.0144301326': 'NRI', '82.839036366727.2551558057': u'Siddharth Nagar', '82.363186452627.6375481721': u'Balrampur', '84.758963425927.2167525497': 'NRI', '83.304025666926.4945537022': u'Gorakhpur', '84.537224398327.7874223025': 'NRI', '83.307801958626.682928406': u'Gorakhpur', '82.360861991927.4490992222': u'Balrampur', '83.799477151227.2392381027': u'Kushinagar', '82.590846327226.6927732641': u'Basti', '84.263041700826.6641846193': u'Kushinagar', '84.307638234428.1697425186': 'NRI', '82.829871621126.6898934851': u'Basti', '83.327248286127.6247188625': 'NRI', '82.596132913727.0696673221': u'Basti', '83.323282798527.436371945': 'NRI', '83.082739474727.440176308': u'Siddharth Nagar', '84.273867250327.040610719': u'Pashchim Champaran', '83.075731127427.0634049612': u'Sant Kabir Nagar', '82.365533588127.8259918172': 'NRI', '84.784750658227.9691168517': 'NRI', '84.049785794627.6107084873': 'NRI', '82.349574108226.5067757959': u'Ambedkar Nagar', '82.598815269727.258106423': u'Siddharth Nagar', '83.100867230628.382007662': 'NRI', '83.790139383726.862657047': u'Kushinagar', '84.071065892528.3635900558': 'NRI', '84.27935994727.2288147009': u'Pashchim Champaran', '84.798022966528.3452597696': 'NRI', '83.58608063428.3736606493': 'NRI', '82.593476661726.8812229269': u'Basti', '83.81870695127.9923301386': 'NRI', '82.851680390328.0087631926': 'NRI', '84.290507112327.6052043518': 'NRI', '84.507471498426.8466675746': u'Pashchim Champaran', '83.331252441627.8130601344': 'NRI', '84.268427961726.85240068': u'Pashchim Champaran', '83.581533185128.1853707647': 'NRI', '84.284906437427.4170125902': 'NRI', '83.546696997926.678843662': u'Gorakhpur', '83.813829373527.8040659691': 'NRI', '84.740271385926.6524118899': u'Purba Champaran', '82.615468355328.3886283756': 'NRI', '83.808998775927.6157958853': 'NRI', '82.356280436627.0721855098': u'Balrampur', '84.065668631828.175378806': 'NRI', '84.060323116327.9871614392': 'NRI', '82.858188305728.3855339542': 'NRI', '83.065472477526.4982070701': u'Sant Kabir Nagar', '83.093510811428.0052918908': 'NRI', '84.73416186326.4642857002': u'Purba Champaran', '84.55578045528.3517991574': 'NRI', '84.752671735127.0286453537': 'NRI', '83.54253077826.4905022302': u'Deoria', '84.543350193227.9755543264': 'NRI', '83.319355697527.248019411': u'Maharajganj', '82.372712728528.3912906742': 'NRI', '83.086295159227.6285537221': 'NRI', '83.559443710427.2438342071': u'Maharajganj', '82.604259051827.6349686358': u'Balrampur', '84.54953539828.1636799569': 'NRI', '82.854918664128.1971513399': 'NRI', '83.097171294128.1936525899': 'NRI', '82.832896660826.8783196116': u'Basti', '82.354023018326.8837207986': u'Basti', '82.370296555228.2028630931': 'NRI', '83.315466705727.0596612902': u'Maharajganj', '83.343499785928.3780497863': 'NRI', '84.513306674927.0348310113': u'Pashchim Champaran', '83.072277970226.875011085': u'Sant Kabir Nagar', '84.501693199726.6584979667': u'Pashchim Champaran', '84.019376938826.4812062955': u'Gopalganj', '83.089885519527.8169255923': 'NRI', '83.550904363526.8671794895': u'Kushinagar', '84.296162368127.7933899504': 'NRI', '83.311615549426.8712976119': u'Gorakhpur', '84.039450925627.2342314667': u'Pashchim Champaran', '82.358560040927.2606449929': u'Balrampur', '83.339377900528.1897256251': 'NRI', '82.609809551728.0118093556': 'NRI', '84.313459664928.3579094182': 'NRI', '84.525149297827.4111392222': 'NRI', '84.029315587926.857730646': u'Kushinagar', '84.257708092326.4759625726': u'Gopalganj', '82.848473251527.8203695388': 'NRI', '82.842151464627.4435658184': u'Siddharth Nagar', '84.02432185226.669471395': u'Kushinagar', '84.746441200226.8405317874': u'Purba Champaran', '83.823631856828.1805883623': 'NRI', '84.778209873327.7810355263': 'NRI', '84.519199136927.2229882395': u'Pashchim Champaran'}\n"
     ]
    }
   ],
   "source": [
    "print dictx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.005107113735448365, 322.78446550186936, 11.751488505507496, 0.32481353351886355, 0.00033729681535987766, 0.035625509611691086, 0.005334789087555691, 0.052098059516083595]\n",
      "[242, 242, 242, 242, 47, 14, 33, 33]\n"
     ]
    }
   ],
   "source": [
    "print times\n",
    "print nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2.11037757663e-05\n",
      "1: 1.33382010538\n",
      "2: 0.0485598698575\n",
      "3: 0.00134220468396\n",
      "4: 7.17652798638e-06\n",
      "5: 0.00254467925798\n",
      "6: 0.00016166027538\n",
      "7: 0.00157872907624\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    x = times[i]/nums[i]\n",
    "    print (str(i) + \": \" + str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- [1] & [2] are the most time consuming\n",
    "- [1] is reverse geocoding\n",
    "- [2] is pixel value extraction\n",
    "- move [2] inside the if condition to check if the row exists\n",
    "    - only then we need the pixel value\n",
    "- deal with [1] using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>phosphorus</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1931.000000</td>\n",
       "      <td>1931.000000</td>\n",
       "      <td>1.931000e+03</td>\n",
       "      <td>1931.000000</td>\n",
       "      <td>1.931000e+03</td>\n",
       "      <td>1.931000e+03</td>\n",
       "      <td>1931.000000</td>\n",
       "      <td>1931.000000</td>\n",
       "      <td>1931.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2004.201968</td>\n",
       "      <td>69936.771103</td>\n",
       "      <td>1.556052e+05</td>\n",
       "      <td>0.557224</td>\n",
       "      <td>1.588625e+05</td>\n",
       "      <td>1.567246e+05</td>\n",
       "      <td>861.667570</td>\n",
       "      <td>871.507723</td>\n",
       "      <td>1.950687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.631699</td>\n",
       "      <td>81619.498004</td>\n",
       "      <td>2.151250e+05</td>\n",
       "      <td>0.665363</td>\n",
       "      <td>2.176855e+05</td>\n",
       "      <td>2.170873e+05</td>\n",
       "      <td>476.198957</td>\n",
       "      <td>458.603987</td>\n",
       "      <td>1.102191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>76.944000</td>\n",
       "      <td>108.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2001.000000</td>\n",
       "      <td>6392.500000</td>\n",
       "      <td>6.326000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.545500e+03</td>\n",
       "      <td>6.987500e+03</td>\n",
       "      <td>592.700000</td>\n",
       "      <td>607.830000</td>\n",
       "      <td>1.021009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>41040.000000</td>\n",
       "      <td>7.190000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.574800e+04</td>\n",
       "      <td>7.204800e+04</td>\n",
       "      <td>765.714000</td>\n",
       "      <td>773.600000</td>\n",
       "      <td>1.882997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>111052.000000</td>\n",
       "      <td>2.333050e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.372640e+05</td>\n",
       "      <td>2.285185e+05</td>\n",
       "      <td>1023.702000</td>\n",
       "      <td>1045.679500</td>\n",
       "      <td>2.645009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>545965.000000</td>\n",
       "      <td>1.637000e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.710000e+06</td>\n",
       "      <td>1.710000e+06</td>\n",
       "      <td>4755.700000</td>\n",
       "      <td>4076.200000</td>\n",
       "      <td>9.886125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Crop_Year           Area    Production   phosphorus            X1  \\\n",
       "count  1931.000000    1931.000000  1.931000e+03  1931.000000  1.931000e+03   \n",
       "mean   2004.201968   69936.771103  1.556052e+05     0.557224  1.588625e+05   \n",
       "std       3.631699   81619.498004  2.151250e+05     0.665363  2.176855e+05   \n",
       "min    1999.000000       1.000000  0.000000e+00     0.000000  1.000000e+00   \n",
       "25%    2001.000000    6392.500000  6.326000e+03     0.000000  7.545500e+03   \n",
       "50%    2005.000000   41040.000000  7.190000e+04     0.000000  7.574800e+04   \n",
       "75%    2007.000000  111052.000000  2.333050e+05     1.000000  2.372640e+05   \n",
       "max    2010.000000  545965.000000  1.637000e+06     2.000000  1.710000e+06   \n",
       "\n",
       "                 X2           X3           X4        value  \n",
       "count  1.931000e+03  1931.000000  1931.000000  1931.000000  \n",
       "mean   1.567246e+05   861.667570   871.507723     1.950687  \n",
       "std    2.170873e+05   476.198957   458.603987     1.102191  \n",
       "min    1.000000e+00    76.944000   108.800000     0.000000  \n",
       "25%    6.987500e+03   592.700000   607.830000     1.021009  \n",
       "50%    7.204800e+04   765.714000   773.600000     1.882997  \n",
       "75%    2.285185e+05  1023.702000  1045.679500     2.645009  \n",
       "max    1.710000e+06  4755.700000  4076.200000     9.886125  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ricex.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ricex.to_csv(\"ricex_test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<open Collection 'C:\\Users\\deepak\\Desktop\\Repo\\Maps\\Districts\\Census\\Dist.shp:Dist', mode 'r' at 0x41ebf28L>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geometry': 'Polygon',\n",
       " 'properties': OrderedDict([(u'DISTRICT', 'str:28'),\n",
       "              (u'ST_NM', 'str:24'),\n",
       "              (u'ST_CEN_CD', 'int:9'),\n",
       "              (u'DT_CEN_CD', 'int:9'),\n",
       "              (u'censuscode', 'float:14')])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init': u'epsg:4326'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "641"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = timeit.default_timer()\n",
    "for i in range(1000000):\n",
    "    j = 1\n",
    "b = timeit.default_timer() - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.119725337737691"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANDSAT 7,  MONTH: 12, YEAR: 2010\n",
      "['B1.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B2.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B3.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B4.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B5.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B6', 'VCID', '1.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B6', 'VCID', '2.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B7.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B8.TIF']\n",
      "Col:  16321,  Row: 14441\n",
      "['BQA.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "LANDSAT 7,  MONTH: 12, YEAR: 2010\n",
      "['B1.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B2.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B3.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B4.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B5.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B6', 'VCID', '1.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B6', 'VCID', '2.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B7.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B8.TIF']\n",
      "Col:  15861,  Row: 13921\n",
      "['BQA.TIF']\n",
      "Col:   7931,  Row:  6961\n"
     ]
    }
   ],
   "source": [
    "for directory in directories:\n",
    "    \n",
    "    \"\"\" Identifying Month, Year, Spacecraft ID \"\"\"\n",
    "    date = directory.split('\\\\')[-1].split('_')[3] # Change for Win7\n",
    "    satx = directory.split('\\\\')[-1][3]\n",
    "    month = date[4:6]\n",
    "    year = date[0:4]\n",
    "    \n",
    "    print \"LANDSAT {},  MONTH: {}, YEAR: {}\".format(satx,month,year)\n",
    "    \n",
    "    \"\"\" Visiting every GeoTIFF file \"\"\" \n",
    "    for _,_,files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".TIF\"):\n",
    "                print filename.split(\"\\\\\")[-1].split(\"_\")[7:]\n",
    "                ds = gdal.Open(os.path.join(directory,filename))\n",
    "                if ds == None: continue\n",
    "                col, row, _ = ds.RasterXSize, ds.RasterYSize, ds.RasterCount\n",
    "                xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
    "                print \"Col: {0:6},  Row:{1:6}\".format(col,row)\n",
    "                \n",
    "                \"\"\" Now go to each pixel, find its lat,lon. Hence its district, and the pixel value \"\"\"\n",
    "                \"\"\" Find the row with same (Year,District), in Crop Dataset. \"\"\"\n",
    "                \"\"\" Find the feature using Month, Band, SATx \"\"\"\n",
    "                \"\"\" For this have to find Mean & Variance \"\"\"\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for LANDSAT 7:  col,row ~ **8000,7000**, with an exception of Band 8, with **16K,14K**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Pseudo Code\n",
    "---\n",
    "> Go to the base folder: extract every zip file, which is unextracted:\n",
    ">> For each folder present here:\n",
    ">>> For each tiff file (for each band):\n",
    ">>>> Identify the following:\n",
    "- Month, Year\n",
    "- District Name\n",
    "- Cloud Cover Percentage\n",
    "- Sat 7 or 8 (maybe from #files in the folder!\n",
    "\n",
    ">>>> According to SAT, meaning of bands change ...(Put them in corresponding features ...)\n",
    "\n",
    ">>>> Traverse every 100th pixel (for sat7 every Kth)\n",
    "\n",
    "----\n",
    "- *Month, Year, Spacecraft ID* all from the **File Name** itself\n",
    "- Regarding the pixel location selection:\n",
    "    - Either go for **definite points** at some gap and avg the **non zero ones**\n",
    "    - OR Can select the points **randomly** and avg the non zero ones only.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
