{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Features from GeoTiff Files\n",
    "From GeoTiff Files available for India over a period of more than 20 years, we want to generate features from those files for the problem of prediction of district wise crop yield in India."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to gdal package, had to make a separate environment using conda. So install packages for this notebook in that environment itself. Check from the anaconda prompt, the names of all the envs are available: $conda info --envs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import ogr, osr, gdal\n",
    "\n",
    "import fiona\n",
    "from shapely.geometry import Point, shape\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Windows\n",
    "``` python\n",
    "base_ = \"C:\\Users\\deepak\\Desktop\\Repo\\Maps\\Districts\\Census_2011\"\n",
    "```\n",
    "- For macOS\n",
    "``` python\n",
    "base_ = \"/Users/macbook/Documents/BTP/Satellite/Data/Maps/Districts/Census_2011\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change this for Win7,macOS\n",
    "base_ = \"C:\\Users\\deepak\\Desktop\\Repo\\Maps\\Districts\\Census_2011\"\n",
    "# base_ = \"/Users/macbook/Documents/BTP/Satellite/Data/Maps/Districts/Census_2011\"\n",
    "fc = fiona.open(base_+\"/2011_Dist.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_geocode(pt):\n",
    "    for feature in fc:\n",
    "        if shape(feature['geometry']).contains(pt):\n",
    "            return feature['properties']['DISTRICT']\n",
    "    return \"NRI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base = \"/Users/macbook/Documents/BTP/Satellite/Data/Sat\" # macOS\n",
    "base = \"G:\\BTP\\Satellite\\Data\\Test\"  # Win7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: G:\\BTP\\Satellite\\Data\\Test\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1.tar.gz\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1.tar.gz\n",
      "Directory: G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_ANG.txt\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_B1.TIF\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_B2.TIF\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_B3.TIF\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_B4.TIF\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_B5.TIF\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_B6_VCID_1.TIF\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_B6_VCID_2.TIF\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_B7.TIF\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_B8.TIF\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_BQA.TIF\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_GCP.txt\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_MTL.txt\n",
      "\tREADME.GTF\n",
      "Directory: G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\gap_mask\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_GM_B1.TIF.gz\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_GM_B2.TIF.gz\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_GM_B3.TIF.gz\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_GM_B4.TIF.gz\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_GM_B5.TIF.gz\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_GM_B6_VCID_1.TIF.gz\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_GM_B6_VCID_2.TIF.gz\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_GM_B7.TIF.gz\n",
      "\tLE07_L1TP_146039_20101223_20161211_01_T1_GM_B8.TIF.gz\n",
      "Directory: G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_ANG.txt\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_B1.TIF\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_B2.TIF\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_B3.TIF\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_B4.TIF\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_B5.TIF\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_B6_VCID_1.TIF\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_B6_VCID_2.TIF\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_B7.TIF\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_B8.TIF\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_BQA.TIF\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_GCP.txt\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_MTL.txt\n",
      "\tREADME.GTF\n",
      "Directory: G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\gap_mask\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_GM_B1.TIF.gz\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_GM_B2.TIF.gz\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_GM_B3.TIF.gz\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_GM_B4.TIF.gz\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_GM_B5.TIF.gz\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_GM_B6_VCID_1.TIF.gz\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_GM_B6_VCID_2.TIF.gz\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_GM_B7.TIF.gz\n",
      "\tLE07_L1TP_146041_20101223_20161211_01_T1_GM_B8.TIF.gz\n"
     ]
    }
   ],
   "source": [
    "b = True\n",
    "for directory, subdirList, fileList in os.walk(base):\n",
    "#     if b:\n",
    "#         b = False\n",
    "#         continue\n",
    "    print (\"Directory: \" + directory)\n",
    "    for filename in fileList:\n",
    "        if filename[0] != '.': print (\"\\t\" + filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(filename, force=False):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "    if os.path.isdir(os.path.join(base,root)) and not force:\n",
    "        # You may override by setting force=True.\n",
    "        print('%s already present - Skipping extraction of %s' % (root, filename))\n",
    "    else:\n",
    "        print('Extracting data for %s' % root)\n",
    "        tar = tarfile.open(os.path.join(base,filename))\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(os.path.join(base,root))\n",
    "        tar.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LE07_L1TP_146039_20101223_20161211_01_T1 already present - Skipping extraction of LE07_L1TP_146039_20101223_20161211_01_T1.tar.gz\n",
      "LE07_L1TP_146041_20101223_20161211_01_T1 already present - Skipping extraction of LE07_L1TP_146041_20101223_20161211_01_T1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# extracting all the tar files ... (if not extracted)\n",
    "for directory, subdirList, fileList in os.walk(base):\n",
    "    for filename in fileList:\n",
    "        if filename.endswith(\".tar.gz\"): \n",
    "            d = extract(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directories = [os.path.join(base, d) for d in sorted(os.listdir(base)) if os.path.isdir(os.path.join(base, d))]\n",
    "# print directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gdal.Open(base + \"\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B1.TIF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare one `ds` variable here itself, for the transformation of the coordinate system below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the existing coordinate system\n",
    "old_cs= osr.SpatialReference()\n",
    "old_cs.ImportFromWkt(ds.GetProjectionRef())\n",
    "\n",
    "# create the new coordinate system\n",
    "wgs84_wkt = \"\"\"\n",
    "GEOGCS[\"WGS 84\",\n",
    "    DATUM[\"WGS_1984\",\n",
    "        SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
    "            AUTHORITY[\"EPSG\",\"7030\"]],\n",
    "        AUTHORITY[\"EPSG\",\"6326\"]],\n",
    "    PRIMEM[\"Greenwich\",0,\n",
    "        AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "    UNIT[\"degree\",0.01745329251994328,\n",
    "        AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "    AUTHORITY[\"EPSG\",\"4326\"]]\"\"\"\n",
    "new_cs = osr.SpatialReference()\n",
    "new_cs.ImportFromWkt(wgs84_wkt)\n",
    "\n",
    "# create a transform object to convert between coordinate systems\n",
    "transform = osr.CoordinateTransformation(old_cs,new_cs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pixel2coord(x, y, xoff, a, b, yoff, d, e):\n",
    "    \"\"\"Returns global coordinates from coordinates x,y of the pixel\"\"\"\n",
    "    xp = a * x + b * y + xoff\n",
    "    yp = d * x + e * y + yoff\n",
    "    return(xp, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>ind_district</th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>phosphorus</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>1999</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>37991.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96800.0</td>\n",
       "      <td>75400.0</td>\n",
       "      <td>643.720</td>\n",
       "      <td>881.473</td>\n",
       "      <td>2.765971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2000</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>39905.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>96800.0</td>\n",
       "      <td>767.351</td>\n",
       "      <td>643.720</td>\n",
       "      <td>2.949004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>32878.0</td>\n",
       "      <td>95609.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>579.338</td>\n",
       "      <td>767.351</td>\n",
       "      <td>2.907993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2002</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>29066.0</td>\n",
       "      <td>66329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95609.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>540.070</td>\n",
       "      <td>579.338</td>\n",
       "      <td>2.282013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2005</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>25008.0</td>\n",
       "      <td>69972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85051.0</td>\n",
       "      <td>44891.0</td>\n",
       "      <td>819.700</td>\n",
       "      <td>564.500</td>\n",
       "      <td>2.797985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_Name ind_district  Crop_Year  Season  Crop     Area  Production  \\\n",
       "0  Andhra Pradesh    anantapur       1999  kharif  Rice  37991.0    105082.0   \n",
       "1  Andhra Pradesh    anantapur       2000  kharif  Rice  39905.0    117680.0   \n",
       "2  Andhra Pradesh    anantapur       2001  kharif  Rice  32878.0     95609.0   \n",
       "3  Andhra Pradesh    anantapur       2002  kharif  Rice  29066.0     66329.0   \n",
       "4  Andhra Pradesh    anantapur       2005  kharif  Rice  25008.0     69972.0   \n",
       "\n",
       "   phosphorus        X1        X2       X3       X4     value  \n",
       "0         0.0   96800.0   75400.0  643.720  881.473  2.765971  \n",
       "1         0.0  105082.0   96800.0  767.351  643.720  2.949004  \n",
       "2         0.0  117680.0  105082.0  579.338  767.351  2.907993  \n",
       "3         0.0   95609.0  117680.0  540.070  579.338  2.282013  \n",
       "4         0.0   85051.0   44891.0  819.700  564.500  2.797985  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ricep = pd.read_csv(\"C:\\Users\\deepak\\Desktop\\Repo\\BTP\\Ricep.csv\")\n",
    "ricep = ricep.drop([\"Unnamed: 0\"],axis=1)\n",
    "ricep[\"value\"] = ricep[\"Production\"]/ricep[\"Area\"]\n",
    "ricep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New features\n",
    "----\n",
    "> 12 months (Numbered 1 to 12)\n",
    ">> 10 TIF files (12 for SAT_8)\n",
    ">>> Mean & Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.empty((ricep.shape[0],1))*np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "dictn = {}\n",
    "k = 13\n",
    "for i in range(1,13):\n",
    "    for j in range(1,11):\n",
    "        s = str(i) + \"_B\" + str(j) + \"_\"\n",
    "        features.append(s+\"M\")\n",
    "        features.append(s+\"V\")\n",
    "        dictn[s+\"M\"] = k\n",
    "        dictn[s+\"V\"] = k+1\n",
    "        k = k+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,13):\n",
    "    for j in range(1,11):\n",
    "        s = str(i) + \"_B\" + str(j) + \"_\"\n",
    "        features.append(s+\"Mn\")\n",
    "        features.append(s+\"Vn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(index=range(ricep.shape[0]),columns=features)\n",
    "ricex = pd.concat([ricep,tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>ind_district</th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>phosphorus</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>...</th>\n",
       "      <th>12_B6_Mn</th>\n",
       "      <th>12_B6_Vn</th>\n",
       "      <th>12_B7_Mn</th>\n",
       "      <th>12_B7_Vn</th>\n",
       "      <th>12_B8_Mn</th>\n",
       "      <th>12_B8_Vn</th>\n",
       "      <th>12_B9_Mn</th>\n",
       "      <th>12_B9_Vn</th>\n",
       "      <th>12_B10_Mn</th>\n",
       "      <th>12_B10_Vn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>1999</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>37991.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96800.0</td>\n",
       "      <td>75400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2000</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>39905.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>96800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>32878.0</td>\n",
       "      <td>95609.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>105082.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2002</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>29066.0</td>\n",
       "      <td>66329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95609.0</td>\n",
       "      <td>117680.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>anantapur</td>\n",
       "      <td>2005</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>25008.0</td>\n",
       "      <td>69972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85051.0</td>\n",
       "      <td>44891.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 493 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_Name ind_district  Crop_Year  Season  Crop     Area  Production  \\\n",
       "0  Andhra Pradesh    anantapur       1999  kharif  Rice  37991.0    105082.0   \n",
       "1  Andhra Pradesh    anantapur       2000  kharif  Rice  39905.0    117680.0   \n",
       "2  Andhra Pradesh    anantapur       2001  kharif  Rice  32878.0     95609.0   \n",
       "3  Andhra Pradesh    anantapur       2002  kharif  Rice  29066.0     66329.0   \n",
       "4  Andhra Pradesh    anantapur       2005  kharif  Rice  25008.0     69972.0   \n",
       "\n",
       "   phosphorus        X1        X2    ...     12_B6_Mn  12_B6_Vn  12_B7_Mn  \\\n",
       "0         0.0   96800.0   75400.0    ...          NaN       NaN       NaN   \n",
       "1         0.0  105082.0   96800.0    ...          NaN       NaN       NaN   \n",
       "2         0.0  117680.0  105082.0    ...          NaN       NaN       NaN   \n",
       "3         0.0   95609.0  117680.0    ...          NaN       NaN       NaN   \n",
       "4         0.0   85051.0   44891.0    ...          NaN       NaN       NaN   \n",
       "\n",
       "  12_B7_Vn 12_B8_Mn 12_B8_Vn 12_B9_Mn 12_B9_Vn 12_B10_Mn 12_B10_Vn  \n",
       "0      NaN      NaN      NaN      NaN      NaN       NaN       NaN  \n",
       "1      NaN      NaN      NaN      NaN      NaN       NaN       NaN  \n",
       "2      NaN      NaN      NaN      NaN      NaN       NaN       NaN  \n",
       "3      NaN      NaN      NaN      NaN      NaN       NaN       NaN  \n",
       "4      NaN      NaN      NaN      NaN      NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 493 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ricex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B2.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B3.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B4.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B5.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B6_VCID_1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B6_VCID_2.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B7.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B8.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_BQA.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B2.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B3.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B4.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B5.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B6_VCID_1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B6_VCID_2.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B7.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_B8.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test\\LE07_L1TP_146041_20101223_20161211_01_T1\\LE07_L1TP_146041_20101223_20161211_01_T1_BQA.TIF\n"
     ]
    }
   ],
   "source": [
    "for directory in directories:\n",
    "    \n",
    "    \"\"\" Identifying Month, Year, Spacecraft ID \"\"\"\n",
    "    date = directory.split('\\\\')[-1].split('_')[3] # Change for Win7\n",
    "    satx = directory.split('\\\\')[-1][3]\n",
    "    month = date[4:6]\n",
    "    year = date[0:4]\n",
    "    \n",
    "    \"\"\" Visiting every GeoTIFF file \"\"\" \n",
    "    for _,_,files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".TIF\"):\n",
    "                print os.path.join(directory,filename)\n",
    "                ds = gdal.Open(os.path.join(directory,filename))\n",
    "                if ds == None: continue\n",
    "                col, row, _ = ds.RasterXSize, ds.RasterYSize, ds.RasterCount\n",
    "                xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
    "                \n",
    "                \"\"\" Now go to each pixel, find its lat,lon. Hence its district, and the pixel value \"\"\"\n",
    "                \"\"\" Find the row with same (Year,District), in Crop Dataset. \"\"\"\n",
    "                \"\"\" Find the feature using Month, Band, SATx \"\"\"\n",
    "                \"\"\" For this have to find Mean & Variance \"\"\"\n",
    "                \n",
    "                for i in range(0,col,col/k):\n",
    "                    for j in range(0,row,row/k):\n",
    "                        \n",
    "                        ########### fetching the lat and lon coordinates \n",
    "                        x,y = pixel2coord(i,j)\n",
    "                        lonx, latx, z = transform.TransformPoint(x,y)\n",
    "                        \n",
    "                        ########### fetching the name of district\n",
    "                        point = Point(lonx,latx)\n",
    "                        district = reverse_geocode(point)\n",
    "                        if district == \"NRI\": continue\n",
    "                        \n",
    "                        ########### The pixel value for that location\n",
    "                        px,py = i,j\n",
    "                        pix = ds.ReadAsArray(px,py,1,1)\n",
    "                        pix = pix[0][0]\n",
    "                        \n",
    "                        ########### Locating the row in DataFrame which we want to update\n",
    "                        r = ricex.loc[ (ricex.ind_district == district) & (ricex.Crop_Year == int(year)) ]\n",
    "                        if r.shape[0] == 1:\n",
    "                            \"\"\" Found the row, so now ..\"\"\"\n",
    "                            \"\"\" Finding Collumn corresponding to Month, Band \"\"\"\n",
    "                            ####### Band Number ########\n",
    "                            band = filename.split(\"\\\\\")[-1].split(\"_\")[7:][0].split(\".\")[0][1]\n",
    "                            bnd = band\n",
    "                            if band == '6':\n",
    "                                if filename.split(\"\\\\\")[-1].split(\"_\")[7:][2][0] == '1':\n",
    "                                    bnd = band\n",
    "                                else:\n",
    "                                    bnd = '9'\n",
    "                            elif band == 'Q':\n",
    "                                bnd = '10'\n",
    "                            \n",
    "                            sm = int(month) + \"_B\" + bnd +\"_M\"\n",
    "                            sv = int(month) + \"_B\" + bnd +\"_V\"\n",
    "                            \n",
    "                            cm = dictn[sm]\n",
    "                            cv = dictn[sv]\n",
    "                            \n",
    "                            # cm,cv are the collumn numbers\n",
    "                            # How to get the row number of the row we want to update ??\n",
    "                            \n",
    "                            \n",
    "                        else:\n",
    "                            print (\"No match for the district \" + district)\n",
    "                        \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANDSAT 7,  MONTH: 12, YEAR: 2010\n",
      "['B1.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B2.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B3.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B4.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B5.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B6', 'VCID', '1.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B6', 'VCID', '2.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B7.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "['B8.TIF']\n",
      "Col:  16321,  Row: 14441\n",
      "['BQA.TIF']\n",
      "Col:   8161,  Row:  7221\n",
      "LANDSAT 7,  MONTH: 12, YEAR: 2010\n",
      "['B1.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B2.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B3.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B4.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B5.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B6', 'VCID', '1.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B6', 'VCID', '2.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B7.TIF']\n",
      "Col:   7931,  Row:  6961\n",
      "['B8.TIF']\n",
      "Col:  15861,  Row: 13921\n",
      "['BQA.TIF']\n",
      "Col:   7931,  Row:  6961\n"
     ]
    }
   ],
   "source": [
    "for directory in directories:\n",
    "    \n",
    "    \"\"\" Identifying Month, Year, Spacecraft ID \"\"\"\n",
    "    date = directory.split('\\\\')[-1].split('_')[3] # Change for Win7\n",
    "    satx = directory.split('\\\\')[-1][3]\n",
    "    month = date[4:6]\n",
    "    year = date[0:4]\n",
    "    \n",
    "    print \"LANDSAT {},  MONTH: {}, YEAR: {}\".format(satx,month,year)\n",
    "    \n",
    "    \"\"\" Visiting every GeoTIFF file \"\"\" \n",
    "    for _,_,files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".TIF\"):\n",
    "                print filename.split(\"\\\\\")[-1].split(\"_\")[7:]\n",
    "                ds = gdal.Open(os.path.join(directory,filename))\n",
    "                if ds == None: continue\n",
    "                col, row, _ = ds.RasterXSize, ds.RasterYSize, ds.RasterCount\n",
    "                xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
    "                print \"Col: {0:6},  Row:{1:6}\".format(col,row)\n",
    "                \n",
    "                \"\"\" Now go to each pixel, find its lat,lon. Hence its district, and the pixel value \"\"\"\n",
    "                \"\"\" Find the row with same (Year,District), in Crop Dataset. \"\"\"\n",
    "                \"\"\" Find the feature using Month, Band, SATx \"\"\"\n",
    "                \"\"\" For this have to find Mean & Variance \"\"\"\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for LANDSAT 7:  col,row ~ **8000,7000**, with an exception of Band 8, with **16K,14K**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Pseudo Code\n",
    "---\n",
    "> Go to the base folder: extract every zip file, which is unextracted:\n",
    ">> For each folder present here:\n",
    ">>> For each tiff file (for each band):\n",
    ">>>> Identify the following:\n",
    "- Month, Year\n",
    "- District Name\n",
    "- Cloud Cover Percentage\n",
    "- Sat 7 or 8 (maybe from #files in the folder!\n",
    "\n",
    ">>>> According to SAT, meaning of bands change ...(Put them in corresponding features ...)\n",
    "\n",
    ">>>> Traverse every 100th pixel (for sat7 every Kth)\n",
    "\n",
    "----\n",
    "- *Month, Year, Spacecraft ID* all from the **File Name** itself\n",
    "- Regarding the pixel location selection:\n",
    "    - Either go for **definite points** at some gap and avg the **non zero ones**\n",
    "    - OR Can select the points **randomly** and avg the non zero ones only.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
